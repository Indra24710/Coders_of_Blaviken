{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jatayu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzwwg6cu5qjG",
        "colab_type": "text"
      },
      "source": [
        "**Proactive Crime/Criminal Recognition System**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFEoEOHBwdSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "3a94b022-58e3-4f0f-9991-63be22d1e752"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/My\\ Drive\n",
        "# !pip install mxnet\n",
        "# !pip install -r requirements.txt\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import random as rd\n",
        "# from collections import Counter\n",
        "# !pip install autopep8\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZpZyLYsZw0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaOipfvU5-pP",
        "colab_type": "text"
      },
      "source": [
        "**Face Recognition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6_hLJY3595m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def facerec():\n",
        "  !chmod +x tasks/train.sh\n",
        "  while True:\n",
        "    !python -m inference.classifier --image-path 'test' --save-dir ' '\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGxI05LWRNpP",
        "colab_type": "text"
      },
      "source": [
        "**Violence Detection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqPKH80xRMzX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "c1567490-2da5-4716-a968-786986c52eae"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import sys\n",
        "sys.path.insert(0,'violence-recognition-pytorch/')\n",
        "from createModel import ViolenceModel\n",
        "from makeDataset import makeDataset\n",
        "from spatial_transforms import *\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def violence():\n",
        "\n",
        "  seqLen=5\n",
        "  mean=[0.485, 0.456, 0.406]\n",
        "  std=[0.229, 0.224, 0.225]\n",
        "  normalize = Normalize(mean=mean, std=std)\n",
        "  numWorkers=4\n",
        "\n",
        "  def make_split(fights_dir, noFights_dir):\n",
        "      imagesF = []\n",
        "      for target in sorted(os.listdir(fights_dir)):\n",
        "          d = os.path.join(fights_dir, target)\n",
        "          if not os.path.isdir(d):\n",
        "              continue\n",
        "          imagesF.append(d)\n",
        "      imagesNoF = []\n",
        "      for target in sorted(os.listdir(noFights_dir)):\n",
        "          d = os.path.join(noFights_dir, target)\n",
        "          if not os.path.isdir(d):\n",
        "              continue\n",
        "          imagesNoF.append(d)\n",
        "      Dataset = imagesF + imagesNoF\n",
        "      Labels = list([1] * len(imagesF)) + list([0] * len(imagesNoF))\n",
        "      NumFrames = [len(glob.glob1(Dataset[i], \"*.jpg\")) for i in range(len(Dataset))]\n",
        "      return Dataset, Labels, NumFrames\n",
        "\n",
        "  for i in li:\n",
        "    model=torch.load('violence-recognition-pytorch/experiments_violence/bestModel.pth')\n",
        "    model.train=False\n",
        "    testDataset=[i]\n",
        "    testLabels=[1,1,1,1,1,0,0,0,0]\n",
        "    numTestInstances=9\n",
        "    test_spatial_transform = Compose([Scale(256), CenterCrop(224), FlippedImagesTest(mean=mean, std=std)])\n",
        "    testBatchSize = 9\n",
        "    numCorrTest=0 \n",
        "    testIter = 0\n",
        "  \n",
        "    testLossEpoch = 0\n",
        "\n",
        "    frame_length=[]\n",
        "    for i in testDataset:\n",
        "      frame_length.append(len(os.listdir(i))-2)\n",
        "    #print(frame_length)\n",
        "    vidSeqTest = makeDataset(testDataset, testLabels, frame_length, seqLen=seqLen,\n",
        "    spatial_transform=test_spatial_transform)\n",
        "\n",
        "    testloader=torch.utils.data.DataLoader(vidSeqTest, batch_size=testBatchSize,\n",
        "                                shuffle=False, num_workers=int(numWorkers/2), pin_memory=True)\n",
        "    for j,(inputs,targets) in enumerate(testloader):\n",
        "      testIter += 1\n",
        "\n",
        "      inputVariable1 = Variable(inputs[0].cuda(), volatile=True)\n",
        "      outputLabel=model(inputVariable1)\n",
        "      outputLabel_mean=torch.mean(outputLabel,0,True)\n",
        "      outputProb = torch.nn.Softmax(dim=1)(outputLabel)\n",
        "      _, predicted = torch.max(outputProb.data, 1)\n",
        "      numCorrTest += (predicted == targets[0]).sum()\n",
        "      \n",
        "    #predicted.print()\n",
        "    print(outputProb)\n",
        "    output.append(predicted)\n",
        "    testAccuracy = (numCorrTest // numTestInstances) * 100\n",
        "    avgTestLoss = testLossEpoch // testIter\n",
        "    #print('Testing: Loss = {} | Accuracy = {}% '.format(avgTestLoss, testAccuracy))\n",
        "\n",
        "\n",
        "\n",
        "li=['FightDIRTest/95','FightDIRTest/96','FightDIRTest/97','FightDIRTest/98','FightDIRTest/99','nofightDIRTest/newfi96','nofightDIRTest/newfi97','nofightDIRTest/newfi98','nofightDIRTest/newfi99']\n",
        "output=[]\n",
        "violence()\n",
        "print(output)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:649: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0444, 0.9556],\n",
            "        [0.0182, 0.9818]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0318, 0.9682],\n",
            "        [0.0361, 0.9639]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "tensor([[0.1433, 0.8567],\n",
            "        [0.1494, 0.8506]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "tensor([[0.0498, 0.9502],\n",
            "        [0.0556, 0.9444]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "tensor([[0.0487, 0.9513],\n",
            "        [0.0240, 0.9760]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "tensor([[0.9971, 0.0029],\n",
            "        [0.9980, 0.0020]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "tensor([[0.9934, 0.0066],\n",
            "        [0.9977, 0.0023]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "tensor([[0.9979, 0.0021],\n",
            "        [0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "tensor([[0.9650, 0.0350],\n",
            "        [0.9759, 0.0241]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "[tensor([1, 1], device='cuda:0'), tensor([1, 1], device='cuda:0'), tensor([1, 1], device='cuda:0'), tensor([1, 1], device='cuda:0'), tensor([1, 1], device='cuda:0'), tensor([0, 0], device='cuda:0'), tensor([0, 0], device='cuda:0'), tensor([0, 0], device='cuda:0'), tensor([0, 0], device='cuda:0')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-mwgLIfVzFo",
        "colab_type": "text"
      },
      "source": [
        "**Jatayu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn4sngShVyfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import threading\n",
        "t1=threading.Thread(target=facerec)\n",
        "#t2=threading.Thread(target=violence)\n",
        "t1.start()\n",
        "#t2.start()\n",
        "t1.join()\n",
        "#t2.join()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBXosUKHwB62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m inference.classifier -h --image-path 'test' --save-dir ' '\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWb2GCK03Ct0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}